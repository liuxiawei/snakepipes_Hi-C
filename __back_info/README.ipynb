{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 配置环境\n",
    "使用HiC-Pro中的yml文件创建conda环境\n",
    "```\n",
    "mamba env create -f environment.yml\n",
    "```\n",
    "\n",
    "接下来按照github readme文件make configure和make install\n",
    "\n",
    "激活环境\n",
    "```\n",
    "conda activate HiC-Pro_v3.1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 酶切图谱\n",
    "```\n",
    "python /lustre1/chengqiyi_pkuhpc/zhaohn/0.apps/HiC-Pro_installed/HiC-Pro_3.1.0/bin/utils/digest_genome.py \\\n",
    "    -r hindiii \\\n",
    "    -o hg38_hindiii.bed \\\n",
    "    /lustre1/chengqiyi_pkuhpc/zhaohn/1.database/db_genomes/genome_fa/genome_ucsc_hg38/genome_ucsc_hg38.fa\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 染色体长度\n",
    "fasta的fai文件中的前两列信息就是长度\n",
    "```\n",
    "samtools faidx /lustre1/chengqiyi_pkuhpc/zhaohn/1.database/db_genomes/genome_fa/genome_ucsc_hg38/genome_ucsc_hg38.fa\n",
    "\n",
    "cut -f1-2 /lustre1/chengqiyi_pkuhpc/zhaohn/1.database/db_genomes/genome_fa/genome_ucsc_hg38/genome_ucsc_hg38.fa.fai > chrom_hg38.sizes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下载测试文件\n",
    "```\n",
    "wget  https://zerkalo.curie.fr/partage/HiC-Pro/HiCPro_testdata.tar.gz && tar -zxvf HiCPro_testdata.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 集群提交\n",
    "## 生成提交任务脚本\n",
    "```\n",
    "HiC-Pro -i test_data -o out_dir -c config-hicpro.txt -p\n",
    "```\n",
    "## 提交在北极星\n",
    "```\n",
    "sbatch HiCPro_step1_ZHN-HiC.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 软件目录script下的make_slurm_script.sh需要修改\n",
    "\n",
    "【直接复制】\n",
    "\n",
    "```shell\n",
    "#!/bin/bash\n",
    "\n",
    "## HiC-Pro\n",
    "## Copyright (c) 2015 Institut Curie                               \n",
    "## Author(s): Nicolas Servant\n",
    "## Contact: nicolas.servant@curie.fr\n",
    "## This software is distributed without any guarantee under the terms of the BSD-3 licence.\n",
    "## See the LICENCE file for details\n",
    "\n",
    "##\n",
    "## Create SLURM Torque files\n",
    "##\n",
    "\n",
    "dir=$(dirname $0)\n",
    "\n",
    "usage()\n",
    "{\n",
    "    echo \"usage: $0 -c CONFIG [-s STEP]\"\n",
    "}\n",
    "\n",
    "MAKE_OPTS=\"\"\n",
    "\n",
    "while [ $# -gt 0 ]\n",
    "do\n",
    "    case \"$1\" in\n",
    "    (-c) conf_file=$2; shift;;\n",
    "\t(-s) MAKE_OPTS=$2; shift;;\n",
    "    (--) shift; break;;\n",
    "    (-*) echo \"$0: error - unrecognized option $1\" 1>&2; exit 1;;\n",
    "    (*)  suffix=$1; break;;\n",
    "    esac\n",
    "    shift\n",
    "done\n",
    "\n",
    "if [ -z \"$conf_file\" ]; then usage; exit 1; fi\n",
    "\n",
    "CONF=$conf_file . $dir/hic.inc.sh\n",
    "unset FASTQFILE\n",
    "\n",
    "## Define input files\n",
    "if [[ $MAKE_OPTS == \"\" || $MAKE_OPTS == *\"mapping\"* ]]\n",
    "then\n",
    "    inputfile=inputfiles_${JOB_NAME}.txt\n",
    "    ifq=$(get_hic_files $RAW_DIR .fq)\n",
    "    ifastq=$(get_hic_files $RAW_DIR .fastq)\n",
    "    echo -e \"$ifq\\n$ifastq\" | grep $PAIR1_EXT | sed -e \"s|$RAW_DIR||\" -e \"s|^/||\" > $inputfile\n",
    "    count=$(cat $inputfile | wc -l)\n",
    "elif [[ $MAKE_OPTS == *\"proc_hic\"* ]]\n",
    "then\n",
    "    inputfile=inputfiles_${JOB_NAME}.txt\n",
    "    get_hic_files $RAW_DIR .bam | grep $PAIR1_EXT | sed -e \"s|$RAW_DIR||\" -e \"s|^/||\" > $inputfile\n",
    "    count=$(cat $inputfile | wc -l)\n",
    "fi\n",
    "\n",
    "## Paralelle Implementation\n",
    "if [[ $MAKE_OPTS == \"\" || $MAKE_OPTS == *\"mapping\"* || $MAKE_OPTS == *\"proc_hic\"* ]]\n",
    "then\n",
    "    make_target=\"all_sub\"\n",
    "    ## Remove per sample steps\n",
    "    if [[ $MAKE_OPTS != \"\" ]]; then \n",
    "    make_target=$(echo $MAKE_OPTS | sed -e 's/,/ /g'); \n",
    "    make_target=$(echo $make_target | sed -e 's/merge_persample//g');\n",
    "    make_target=$(echo $make_target | sed -e 's/build_contact_maps//g');\n",
    "    make_target=$(echo $make_target | sed -e 's/ice_norm//g');\n",
    "        make_target=$(echo $make_target | sed -e 's/quality_checks//g');\n",
    "    fi\n",
    " \n",
    "    ## step 1 - parallel\n",
    "    torque_script=HiCPro_step1_${JOB_NAME}.sh\n",
    " \n",
    "    cat > ${torque_script} <<EOF\n",
    "#!/bin/bash\n",
    "#SBATCH -N 1\n",
    "#SBATCH -c ${N_CPU}\n",
    "#SBATCH -p ${JOB_QUEUE}\n",
    "\n",
    "#SBATCH --job-name=s1_${JOB_NAME}_HiCpro\n",
    "#SBATCH --export=ALL\n",
    "#SBATCH --no-requeue\n",
    "#SBATCH -A ${JOB_ACCOUNT}\n",
    "#SBATCH --qos=${JOB_QOS}\n",
    "EOF\n",
    "    \n",
    "    if [[ $count -gt 1 ]]; then\n",
    "\techo -e \"#SBATCH --array=1-$count\" >> ${torque_script}\n",
    "    fi\n",
    "    cat >> ${torque_script} <<EOF\n",
    "FASTQFILE=\\$SLURM_SUBMIT_DIR/$inputfile; export FASTQFILE\n",
    "make --file ${SCRIPTS}/Makefile CONFIG_FILE=${conf_file} CONFIG_SYS=${INSTALL_PATH}/config-system.txt $make_target 2>&1\n",
    "EOF\n",
    "    \n",
    "    chmod +x ${torque_script}\n",
    "\n",
    "    ## User message\n",
    "    echo \"The following command will launch the parallel workflow through $count torque jobs:\"\n",
    "    echo sbatch ${torque_script}\n",
    "fi    \n",
    "\n",
    "\n",
    "## Per sample Implementation\n",
    "if [[ $MAKE_OPTS == \"\" || $MAKE_OPTS == *\"build_contact_maps\"* || $MAKE_OPTS == *\"ice_norm\"* || $MAKE_OPTS == *\"quality_checks\"* ]]\n",
    "then\n",
    "    make_target=\"all_persample\"\n",
    "    ## Remove parallele mode\n",
    "    if [[ $MAKE_OPTS != \"\" ]]; \n",
    "    then \n",
    "\tmake_target=$(echo $MAKE_OPTS | sed -e 's/,/ /g'); \n",
    "\tmake_target=$(echo $make_target | sed -e 's/mapping//g');\n",
    "\tmake_target=$(echo $make_target | sed -e 's/proc_hic//g');\n",
    "    fi\n",
    "\n",
    "    torque_script_s2=HiCPro_step2_${JOB_NAME}.sh\n",
    "    cat > ${torque_script_s2} <<EOF\n",
    "#!/bin/bash\n",
    "\n",
    "#SBATCH -N 1\n",
    "#SBATCH -c 1\n",
    "#SBATCH -p ${JOB_QUEUE}\n",
    "\n",
    "#SBATCH --job-name=s2_${JOB_NAME}_HiCpro\n",
    "#SBATCH --export=ALL\n",
    "#SBATCH --no-requeue\n",
    "#SBATCH -A ${JOB_ACCOUNT}\n",
    "#SBATCH --qos=${JOB_QOS}\n",
    "\n",
    "cd \\$SLURM_SUBMIT_DIR\n",
    "\n",
    "make --file ${SCRIPTS}/Makefile CONFIG_FILE=${conf_file} CONFIG_SYS=${INSTALL_PATH}/config-system.txt $make_target 2>&1\n",
    "EOF\n",
    "    \n",
    "    chmod +x ${torque_script_s2}\n",
    "\n",
    "    ## User message\n",
    "    echo \"The following command will merge the processed data and run the remaining steps per sample:\"\n",
    "    echo sbatch ${torque_script_s2}\n",
    "fi\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config file\n",
    "```shell\n",
    "# Copy and edit the configuration file ‘config-hicpro.txt’ in your local folder. \n",
    "# \n",
    "# The ‘[]’ options are optional and can be undefined.\n",
    "# 带有[]中括号的参数可以不定义，为可选参数\n",
    "# Please change the variable settings below if necessary\n",
    "#########################################################################\n",
    "## Paths and Settings  - Do not edit !\n",
    "## 输入输出文件路径，尽量不动\n",
    "#########################################################################\n",
    "TMP_DIR = tmp\n",
    "\n",
    "LOGS_DIR = logs\n",
    "\n",
    "BOWTIE2_OUTPUT_DIR = bowtie_results\n",
    "\n",
    "MAPC_OUTPUT = hic_results\n",
    "\n",
    "# Link to rawdata folder. The user usually not need to change this option\n",
    "# 尽量不该rawdata路径\n",
    "RAW_DIR = rawdata\n",
    "\n",
    "#######################################################################\n",
    "## SYSTEM AND SCHEDULER - Start Editing Here !!\n",
    "## 从这里开始编辑\n",
    "#######################################################################\n",
    "# ?文档中没有说明\n",
    "SORT_RAM = 1000M\n",
    "\n",
    "# name of the main log file\n",
    "LOGFILE = hicpro.log\n",
    "\n",
    "# 【可选参数】name of the job on the cluster\n",
    "JOB_NAME = ZHN-HiC \n",
    "\n",
    "# 【可选参数】队列指定\n",
    "JOB_ACCOUNT = chengqiyi_g1\n",
    "# 【cnlong】\n",
    "# N_CPU = 20\n",
    "# JOB_QUEUE = cn-long\n",
    "# JOB_QOS = chengqiyicnl\n",
    "\n",
    "# 【cn-short】\n",
    "# N_CPU = 20\n",
    "# JOB_QUEUE = cn-short\n",
    "# JOB_QOS = chengqiyicns\n",
    "\n",
    "# 【cn_nl】\n",
    "N_CPU = 20\n",
    "JOB_QUEUE = cn_nl\n",
    "JOB_QOS = chengqiyicnnl\n",
    "\n",
    "# 【fat4way】\n",
    "# N_CPU = 24\n",
    "# JOB_QUEUE = fat4way\n",
    "# JOB_QOS = chengqiyif4w\n",
    "\n",
    "# 【fat8way】\n",
    "# N_CPU = 64\n",
    "# JOB_QUEUE = fat8way\n",
    "# JOB_QOS = chengqiyif8w\n",
    "#########################################################################\n",
    "## Data\n",
    "#########################################################################\n",
    "# Keyword for first mate detection. Default:_R1\n",
    "PAIR1_EXT = _R1\n",
    "\n",
    "# Keywoard for seconde mate detection. Default:_R2\n",
    "PAIR2_EXT = _R2\n",
    "\n",
    "#######################################################################\n",
    "## Alignment options\n",
    "#######################################################################\n",
    "# Minimum mapping quality. \n",
    "# Reads with lower quality are discarded. \n",
    "# Default: 0\n",
    "MIN_MAPQ = 10\n",
    "\n",
    "# Path to bowtie2 indexes\n",
    "BOWTIE2_IDX_PATH = /lustre1/chengqiyi_pkuhpc/zhaohn/1.database/db_genomes/genome_fa/genome_ucsc_hg38/\n",
    "\n",
    "# bowtie2 options for mapping step1. \n",
    "# Default: –very-sensitive -L 30 –score-min L,-0.6,-0.2 –end-to-end –reorder\n",
    "BOWTIE2_GLOBAL_OPTIONS = --very-sensitive -L 30 --score-min L,-0.6,-0.2 --end-to-end --reorder\n",
    "\n",
    "# bowtie2 options for mapping step2. \n",
    "# Default: –very-sensitive -L 20 –score-min L,-0.6,-0.2 –end-to-end –reorder\n",
    "BOWTIE2_LOCAL_OPTIONS =  --very-sensitive -L 20 --score-min L,-0.6,-0.2 --end-to-end --reorder\n",
    "\n",
    "#######################################################################\n",
    "## Annotation files\n",
    "#######################################################################\n",
    "# Reference genome prefix used for genome indexes. \n",
    "# Default: hg19\n",
    "# 【需要升级为hg38，查阅文档】\n",
    "REFERENCE_GENOME = genome_ucsc_hg38.fa.bowtie2_index\n",
    "\n",
    "# Chromsome size file. \n",
    "# Loaded from the ANNOTATION folder in the HiC-Pro installation directory. \n",
    "# Default: chrom_hg19.sizes\n",
    "# 这个要放到安装文件夹下头！\n",
    "# 【需要升级为hg38，查阅文档】\n",
    "GENOME_SIZE = chrom_hg38.sizes\n",
    "\n",
    "#######################################################################\n",
    "## Allele specific analysis\n",
    "## http://nservant.github.io/HiC-Pro/AS.html#as\n",
    "#######################################################################\n",
    "# VCF file to SNPs which can be used to distinguish parental origin. See the allele specific section for more details\n",
    "# 【可选参数】\n",
    "# ALLELE_SPECIFIC_SNP = \n",
    "\n",
    "#######################################################################\n",
    "## Capture Hi-C analysis\n",
    "#######################################################################\n",
    "# BED file of target regions to focus on (mainly used for capture Hi-C data\n",
    "# 【可选参数】\n",
    "# CAPTURE_TARGET =\n",
    "REPORT_CAPTURE_REPORTER = 1\n",
    "\n",
    "#######################################################################\n",
    "## Digestion Hi-C\n",
    "#######################################################################\n",
    "# BED file with restriction fragments. \n",
    "# Full path or name of file available in the ANNOTATION folder. \n",
    "# Default: HindIII_resfrag_hg19.bed\n",
    "# 含有限制性片段的BED文件\n",
    "# 这个要放到安装文件夹下头！\n",
    "# 【需要升级为hg38，查阅文档】\n",
    "GENOME_FRAGMENT = HindIII_resfrag_hg38.bed\n",
    "\n",
    "# Ligation site sequence used for reads trimming. \n",
    "# Depends on the fill in strategy. \n",
    "# Example: AAGCTAGCTT\n",
    "# 酶的序列，例如：\n",
    "# HindIII，为AAGCTAGCTT\n",
    "# MboI，为GATCGATC\n",
    "LIGATION_SITE = AAGCTAGCTT\n",
    "\n",
    "# Minimum size of restriction fragments to consider for the Hi-C processing.\n",
    "# Example: 100\n",
    "# 为Hi-C处理考虑的限制片段的【最小大小】\n",
    "MIN_FRAG_SIZE = 100\n",
    "\n",
    "# Maximum size of restriction fragments to consider for the Hi-C processing.\n",
    "# Example: 100000\n",
    "# # 为Hi-C处理考虑的限制片段的【最大大小】\n",
    "MAX_FRAG_SIZE = 100000\n",
    "\n",
    "# Minimum sequenced insert size. \n",
    "# Shorter 3C products are discarded. \n",
    "# Example: 100\n",
    "# 测得【最小】插入大小。\n",
    "# 较短的3C产物会被丢弃\n",
    "MIN_INSERT_SIZE = 100\n",
    "\n",
    "# Maximum sequenced insert size. \n",
    "# Larger 3C products are discarded. \n",
    "# Example: 600\n",
    "# 测得【最大】插入大小。\n",
    "# 较短的3C产物会被丢弃\n",
    "MAX_INSERT_SIZE = 600\n",
    "\n",
    "#######################################################################\n",
    "## Hi-C processing\n",
    "#######################################################################\n",
    "# Filter short range contact below the specified distance. \n",
    "# Mainly useful for DNase Hi-C. \n",
    "# Example: 1000\n",
    "MIN_CIS_DIST =\n",
    "\n",
    "# Create output files with all classes of 3C products. \n",
    "# Default: 0\n",
    "GET_ALL_INTERACTION_CLASSES = 1\n",
    "\n",
    "# Create a BAM file with all aligned reads flagged according to \n",
    "# their classifaction and mapping category. \n",
    "# 是否保留BAM文件，默认不保留\n",
    "# Default: 0\n",
    "GET_PROCESS_SAM = 1\n",
    "\n",
    "# Remove singleton reads. \n",
    "# Default: 1\n",
    "RM_SINGLETON = 1\n",
    "\n",
    "# Remove multi-mapped reads. \n",
    "# Default: 1\n",
    "RM_MULTI = 1\n",
    "\n",
    "# Remove duplicated reads’ pairs. \n",
    "# Default: 1\n",
    "RM_DUP = 1\n",
    "\n",
    "#######################################################################\n",
    "## Contact Maps\n",
    "#######################################################################\n",
    "# Resolution of contact maps to generate (space separated). \n",
    "# Default: 20000 40000 150000 500000 1000000\n",
    "BIN_SIZE = 20000 40000 150000 500000 1000000\n",
    "\n",
    "# Binning step size in ‘n’ coverage _i.e._ window step. \n",
    "# Default: 1\n",
    "# BIN_STEP\n",
    "\n",
    "# Output matrix format. \n",
    "# Must be complete, asis, upper or lower. \n",
    "# Default: upper\n",
    "MATRIX_FORMAT = upper\n",
    "\n",
    "#######################################################################\n",
    "## Normalization\n",
    "#######################################################################\n",
    "# Maximum number of iteration for ICE normalization. \n",
    "# Default: 100\n",
    "MAX_ITER = 100\n",
    "\n",
    "# Define which pourcentage of bins with low counts should be force to zero. \n",
    "# Default: 0.02. \n",
    "# Replace SPARSE_FILTERING\n",
    "FILTER_LOW_COUNT_PERC = 0.02\n",
    "\n",
    "# Define which pourcentage of bins with low counts should be discarded \n",
    "# before normalization. \n",
    "# Default: 0\n",
    "FILTER_HIGH_COUNT_PERC = 0\n",
    "\n",
    "# The relative increment in the results before declaring convergence. \n",
    "# Default: 0.1\n",
    "EPS = 0.1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert ValidPairs to Juicer .hic\n",
    "~/0.apps/HiC-Pro_installed/HiC-Pro_3.1.0/bin/utils/hicpro2juicebox.sh -h\n",
    "提示需要Hi Doug,\n",
    "\n",
    "Please take a look at: \n",
    "\n",
    "https://github.com/theaidenlab/juicer/tree/master/AWS/scripts\n",
    "\n",
    "juicebox_tools.jar is located there.\n",
    "\n",
    "juicebox_tools.jar and juicebox_CLT.jar are different names for the same thing.\n",
    "If your script is using CLT, just rename that jar to the correct name.\n",
    "\n",
    "```shell\n",
    "~/0.apps/HiC-Pro_installed/HiC-Pro_3.1.0/bin/utils/hicpro2juicebox.sh -i dixon_2M.allValidPairs -g ~/0.apps/HiC-Pro_installed/HiC-Pro_3.1.0/annotation/chrom_hg38.sizes -j ~/0.apps/juicerbox/juicer_tools.jar -r ~/0.apps/HiC-Pro_installed/HiC-Pro_3.1.0/annotation/HindIII_resfrag_hg38.bed\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# call loop [juicer]\n",
    "https://github.com/aidenlab/juicer\n",
    "\n",
    "http://www.360doc.com/content/19/1224/14/68068867_881786243.shtml\n",
    "\n",
    "juicer采用ArrowHead算法对原始的交互矩阵进行转化，并预测TAD拓扑关联结构域，采用HiCUUPS算法识别染色质环chromatin loops。和其他Hi-C数据处理软件相比，juicer的功能更为齐全\n",
    "\n",
    "```shell\n",
    "Command Line Tools Usage\n",
    "Detailed documentation about the command line tools can be found on the wiki:\n",
    "\n",
    "Annotating features with Arrowhead, HiCCUPS, MotifFinder, APA, Eigenvector, and Pearsons\n",
    "Creating .hic with Pre\n",
    "Extracting data from .hic files with dump\n",
    "To launch the command line tools, use the shell script “juicer_tools” on Unix/MacOS or type\n",
    "\n",
    "java -jar juicer_tools.jar (command...) [flags...] <parameters...>`\n",
    "There are different flavors of juicer_tools that depend on the CUDA version. If you do not use GPUs, these versions are equivalent. Otherwise, juicer_tools.X.X.jar uses CUDA version X.X\n",
    "\n",
    "For HiCCUPS loop calling without the shell or bat script, you will need to call: java -Xms512m -Xmx2048m -Djava.library.path=path/to/natives/ -jar juicer_tools.jar hiccups [flags...] <parameters...> where path/to/natives is the path to the native libraries used for Jcuda By default, these are located in the lib/jcuda folder.\n",
    "\n",
    "In the command line tools, there are several analysis functions:\n",
    "\n",
    "apa for conducting aggregate peak analysis\n",
    "hiccups for annotating loops\n",
    "motifs for finding CTCF motifs\n",
    "arrowhead for annotating contact domains\n",
    "eigenvector for calculating the eigenvector (first PC) of the Pearson's\n",
    "pearsons for calculating the Pearson's\n",
    "The juicer_tools (Unix/MacOS) script can be used in place of the unwieldy java -Djava.library.path=path/to/natives/ -jar juicer_tools.jar\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# call TAD [HiC Explorer / TopDom]\n",
    "/lustre1/chengqiyi_pkuhpc/zhaohn/0.apps/miniconda3/bin/hicexplorer\n",
    "\n",
    "这个链接【重点参考！！！】\n",
    "https://blog.csdn.net/hzau_yang/article/details/100031590\n",
    "```shell\n",
    "hicBuildMatrix --samFiles mate_R1.bam mate_R2.bam \\\n",
    "                 --binSize 10000 \\\n",
    "                 --restrictionSequence GATC \\\n",
    "                 --threads 4\n",
    "                 --inputBufferSize 100000\n",
    "                 --outBam hic.bam \\\n",
    "                 -o hic_matrix.h5\n",
    "                 --QCfolder ./hicQC\n",
    "```\n",
    "\n",
    "该步骤最终生成一个bam文件，一个h5文件，以及一个hicQC文件夹报告，改报告写的比较详细，懂Hi-C的一般都能看懂，里面包含了比对率，数据有效利用率等信息；h5这个文件格式比较复杂，操作起来需要hicmatrix包的HiCMatrix函数；\n",
    "\n",
    "\n",
    "3.校正Hi-C交互矩阵\n",
    "默认使用KR标准化方法，也可以使用ICE，通过–correctionMethod参数控制；\n",
    "–chromosomes控制输出的染色体，通过空格隔开，如chr1 chr2 chr3;\n",
    "\n",
    "```shell\n",
    "# KR 校正\n",
    "hicCorrectMatrix correct -m hic_matrix.h5 --filterThreshold -1.5 5 -o hic_corrected.h5\n",
    "# 画热图\n",
    "hicPlotMatrix -m hic_corrected.h5 -o hic_plot.png --region 1:20000000-80000000 --log1p\n",
    "```\n",
    "该命令可以根据输出文件后缀画出不同的格式图，也可以通过–perChr参数控制每条染色体单独画；\n",
    "\n",
    "\n",
    "找TAD\n",
    "找TAD的软件有很多，hicexplorer的方法与Topdom有点相似，总的来说算比较简单粗暴的，实现\n",
    "hicFindTADs -m hic_corrected.h5 --outPrefix hic_corrected --numberOfProcessors 16\n",
    "\n",
    "# call compartments\n",
    "\n",
    "5.找compartment\n",
    "\n",
    "\n",
    "hicPCA -m hic_corrected.h5 --outFileName pca1.bw pca2.bw --format bigwig --pearsonMatrix pearson.h5\n",
    "\n",
    "通常可以根据基因密度来调整第一主成分的符号，获得最终的compartment；统计完每个bin的基因数量，得到bigwig文件，然后通过–extraTrack可以直接对PCA结果调整符号；也可以通过–pearsonMatrix和–obsexpMatrix生成计算compartment的中间处理中的矩阵，如pearson矩阵；\n",
    "\n",
    "画图\n",
    "\n",
    "hicPlotMatrix -m pearson.h5 --outFileName pca1.png --perChr --bigwig pca1.bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
